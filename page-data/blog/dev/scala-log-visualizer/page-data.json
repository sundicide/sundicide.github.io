{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/blog/dev/scala-log-visualizer/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"results\" style=\"position:relative;\"><a href=\"#results\" aria-label=\"results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Results</h2>\n<p><a href=\"https://codepen.io/sundicide/pen/VwQvrLe\"><div><iframe \n        height='400' \n        scrolling='no' \n        src='//codepen.io/sundicide/embed/preview/VwQvrLe/?height=400&theme-id=dark&default-tab=html,result' \n        frameborder='no' \n        allowtransparency='true' \n        allowfullscreen='true' \n        style='width: 100%;'></iframe></div></a></p>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>사내에서 운영중인 Web Service가 있는데 log를 수집하고 있었다.\n2022년 1월 1일 부터 모아온 log 파일들을 scala-spark로 통계를 내고 이를 Visualize 해보기 위한 Personal Project이다.</p>\n<h2 id=\"description\" style=\"position:relative;\"><a href=\"#description\" aria-label=\"description permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Description</h2>\n<h3 id=\"scala-spark\" style=\"position:relative;\"><a href=\"#scala-spark\" aria-label=\"scala spark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scala, Spark</h3>\n<p>spark를 이용한 로그 분석에서 가장 키가 되는 코드들은 아래 코드이다.\n모든 로그 파일들에서 text들을 분석 한 뒤 필터링 하고 이를 <code class=\"language-text\">groupBy</code>와 <code class=\"language-text\">mapValues + foldLeft</code>로 count를 생성했다.</p>\n<p>마지막에 <code class=\"language-text\">Row</code>로 변환을 해 준 것은 DataFrame 형태로 변환해 결과를 CSV로 만들기 위함이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-scala line-numbers\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> filteredLines<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>Row<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> logLines<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>line <span class=\"token keyword\">=></span> parseLog<span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>filter<span class=\"token punctuation\">(</span>loggerData <span class=\"token keyword\">=></span> loggerData <span class=\"token operator\">!=</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>filter<span class=\"token punctuation\">(</span>loggerData <span class=\"token keyword\">=></span> isValidLog<span class=\"token punctuation\">(</span>loggerData<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>loggerData<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">(</span>loggerData<span class=\"token punctuation\">.</span>getUser<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> loggerData<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>groupBy<span class=\"token punctuation\">(</span>d <span class=\"token keyword\">=></span> d<span class=\"token punctuation\">.</span>_1<span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>mapValues<span class=\"token punctuation\">(</span>d <span class=\"token keyword\">=></span> d<span class=\"token punctuation\">.</span>foldLeft<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>acc<span class=\"token punctuation\">,</span> _<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> acc <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>sortBy<span class=\"token punctuation\">(</span>logPair <span class=\"token keyword\">=></span> logPair<span class=\"token punctuation\">.</span>_2<span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>logPair <span class=\"token keyword\">=></span> Row<span class=\"token punctuation\">(</span>logPair<span class=\"token punctuation\">.</span>_1<span class=\"token punctuation\">,</span> logPair<span class=\"token punctuation\">.</span>_2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>","excerpt":"Results  Introduction 사내에서 운영중인 Web Service가 있는데 log를 수집하고 있었다.\n2022년 1월 1일 부터 모아온 log 파일들을 scala-spark로 통계를 내고 이를 Visualize 해보기 위한 Personal Project…","frontmatter":{"date":"09 May, 2022","path":"/blog/dev/scala-log-visualizer/","title":"Scala Log Visualizer"},"timeToRead":1}},"pageContext":{}},"staticQueryHashes":["2744905544","3649515864","63159454"],"slicesMap":{}}